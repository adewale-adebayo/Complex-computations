{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMM model for unfair Casino Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Hidden Markov Model is a statistical Markov model in which the system being modeled is assumed to be a Markov process with unobserved (i.e. hidden) states. HMM is a Markov model whose states are not directly observed, instead each state is characterised by a probability distribution function that models the observation corresponding to that state. HMM has been extensively used in temporal pattern recognition such as speech, handwriting, gesture recognition, robotics, biological sequences and recently in energy disaggregation. This report presents the basic phenomenon and implementation of HMM in python. The model is then used to simulate the hidden casino problem. The first part of this report gives theoretical basics to the study of hidden markov models. In the second part, we explore the unfair casino problem in detail. The third chapeter presents a step-by -step analysis of what was done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Theoretical Basis of Hidden Markov Model\n",
    "\n",
    "An hidden Markov chain is characterised by two main variables: observed sequence and hidden sequence(which actually forms the Markov process) [1]. A graphical illustration of a hidden markov chain is shown below\n",
    "![Image](https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Hmm_temporal_bayesian_net.svg/1920px-Hmm_temporal_bayesian_net.svg.png)\n",
    "\n",
    "A typical HMM is characterised by the following parameters:\n",
    "<li> Finite set of hidden states :  $S = \\{s_1, s_2....,s_M\\}$\n",
    "<li> Set of observations, $X =\\{x_1, x_2....,s_K\\}$\n",
    "<li>Transition matrix $\\mathbf{P}=\\{p_{ij}: 1\\leq i,j \\leq N\\}$, which represents the probability of changing from state $s_{t-1}=i $ to state  $s_t =j$. Matrix P is an $M \\times M$ matrix\n",
    "<li>Emission or Observation matrix $\\mathbf{E} =\\{e_j(k)\\}$ representing the probability emmision of $k$\n",
    "<li>Initial distribution , $pi= \\{pi_1...pi_M\\}$ which indicates the probability of each state of the hidden variable at time $t=0$\n",
    "    \n",
    "The probabilty function of the observations $X$ is given by the joint distribution of $X$ and $S$ over all possible state.\n",
    "<center>$P(X \\mid (\\pi, P, E)) = \\sum P(X, S \\mid  (\\pi, P, E))$ <center>\n",
    "    \n",
    "Usually there are 3 problems that require solution when using HMMs:\n",
    "<br>\n",
    "1.Evaluation Problem: Finding the probability of obtaining an observation sequence $X$ given the HMM parameters($pi, P, E$)<br>\n",
    "2.Decoding Problem: Finding the optimal hidden state sequence(path) that best explains an observation sequence $O$, given the HMM parameters ($pi,P,E$)\n",
    "3.Learning Problem: Optimization of model parameters to describe the model \n",
    "<div>\n",
    "    \n",
    "Each of this problem can be solved using different algorithms. The most common of which are Viterbi algorithm, Forward algorithm and Backward algorithm \n",
    "\n",
    "These algorithms are implemented to solve the unfair casino problem in the following chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of libraries\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unfair Casino Problem\n",
    "\n",
    "Description of problem:  One dice has equal probabilities of each face\n",
    "and another dice has probability of $P(6) = 0.5$, other outcomesâ€™ probabilities are\n",
    "$0.1$. The probability to switch from the fair dice to the loaded dice is $0.05$, the\n",
    "probability to switch from the loaded to the fair dice is $0.1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition of parameters\n",
    "    Hidden states: \n",
    "    Observed states:\n",
    "    Transition probabilities:\n",
    "    Emmission probabilities:\n",
    "    Initial distribution(stationary distribution):\n",
    "    \n",
    "\n",
    " <h5> Possible transitions </h5> \n",
    " \n",
    "<li> $ Fair \\rightarrow Fair $: $1 -0.05 =.95$ </li>\n",
    "<li>$Fair \\rightarrow Biased$: $0.05 $</li>\n",
    "<li> $Biased \\rightarrow Biased $: $1-0.10=0.90$ </li>\n",
    "<li> $Biased\\rightarrow Biased $: $0.10$ </li>  \n",
    "\n",
    "The fair die is equally likely to produce observations $O=\\{$1,2,3,4,5,6$\\}$,   with probabilities: $Pr(i) = \\frac{1}{2}$\n",
    "<div>For the biased die $Pr(6)=0.5$ and $Pr(1)=Pr(2)=Pr(3)=Pr(4)=Pr(5)=0.1$</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading of files \n",
    "P = np.loadtxt('/Users/adewaleadebayo/Documents/Complex computation programming/HMM/data/trans_mat.txt'\n",
    "               ,usecols=(range(1,3)), skiprows=1 )\n",
    "E = np.loadtxt('/Users/adewaleadebayo/Documents/Complex computation programming/HMM/data/Emis_mat.txt',\n",
    "               usecols=(range(1,7)) ,skiprows=1)\n",
    "pi = np.loadtxt('/Users/adewaleadebayo/Documents/Complex computation programming/HMM/data/init_dist.txt',skiprows=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the model parameters based on the unfair casino example\n",
    "states = fair, biased = 0,1     \n",
    "observations = list(range(1,7))\n",
    "\n",
    "P = np.asarray([[0.95, 0.05],  # Transition matrix between the hidden states\n",
    "             [0.10, 0.90]])\n",
    "\n",
    "O = np.asarray([[1./6 for i in range(6)],    # Emission matrix of observations of each state \n",
    "               [0.1, 0.1, 0.1, 0.1, 0.1, 0.5]])\n",
    "\n",
    "pi = np.asarray([2./3, 1./3])  # We are using the stationary distribution as \n",
    "                               # the initial distribution for the markov chain\n",
    "\n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now based on these parameters we need to produce a sequence of **observed**  and **hidden** states using the Fitness proportion algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_state(weights):\n",
    "    \n",
    "    \"\"\" Determines next state of Markov Chain\n",
    "    \n",
    "    Returns to next state by using the fitness proportion algoritm with the initial distribution as weights\n",
    "    \"\"\"\n",
    "    value = sum(weights) * random.random()\n",
    "    for i,w in enumerate(weights):\n",
    "        value -= w\n",
    "        if value < 0 :\n",
    "            return i "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected number of Fair states: 670\n",
      "Expected number of Biased states: 330\n"
     ]
    }
   ],
   "source": [
    "# Check if selection algorithm works fine \n",
    "count = 0\n",
    "for i in range(1000):\n",
    "    count += select_state(pi)\n",
    "    \n",
    "print (\"Expected number of Fair states:\",1000-count)\n",
    "print (\"Expected number of Biased states:\",count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation of Markov chain Path\n",
    "def generate_hidden_seq(pi,P,L):\n",
    "    \"\"\"Generate sequence of hidden states of size L\n",
    "    \n",
    "    \"\"\"\n",
    "    hid_states = [None] * L\n",
    "    #At time t=0, we use the initial distribution\n",
    "    hid_states[0] = select_state(pi)\n",
    "    for i in range(1,L):\n",
    "        hid_states[i] = select_state(P[hid_states[i-1]])\n",
    "    return hid_states\n",
    "\n",
    "\n",
    "def generate_observations(hid_seq, O):\n",
    "    \"\"\" Generate sequence of observations of size L\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    E: Emission matrix\n",
    "    Hid_seq: Sequence of hidden Markov states\n",
    "    \"\"\"\n",
    "    L = len(hid_seq)\n",
    "    obs = [None] *L\n",
    "    \n",
    "    for i in range(L):\n",
    "        obs[i] = select_state(O[hid_seq[i]])\n",
    "        \n",
    "    return obs\n",
    "    \n",
    "hid_seq = np.asarray(generate_hidden_seq(pi,P,300))\n",
    "obs_seq = np.asarray(generate_observations(hid_seq, O))\n",
    "\n",
    "x = obs_seq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667, 0.16666667, 0.16666667, 0.16666667, 0.16666667,\n",
       "        0.16666667],\n",
       "       [0.1       , 0.1       , 0.1       , 0.1       , 0.1       ,\n",
       "        0.5       ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(x, P, E, pi=None):\n",
    "    \"\"\" Return the most probable path, with the given HMM model and observation sequence\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : observation sequence \n",
    "    P : Transition matrix of hidden chain\n",
    "    E : Emission matrix\n",
    "    pi : Initial distribution of Markov chain(optional)\n",
    "    \"\"\"\n",
    "    T = len(obs_seq) # Time steps\n",
    "    N = P.shape[0]    # number of states\n",
    "    delta = np.zeros((T,N)) # viterbi variable\n",
    "    alpha = np.zeros ((T,N)) # initialise the best path table\n",
    "    \n",
    "# Initialization  \n",
    "    delta[0] = pi * E[:,obs_seq[0]]\n",
    "    \n",
    "# Recursion \n",
    "    for t in range(1,T):\n",
    "        for i in range(N):\n",
    "            delta[t,i] = np.max(delta[t-1]*P[:,i]) * E[i, obs_seq[t]]\n",
    "            alpha[t,i] = np.argmax(delta[t-1]*P[:,i])\n",
    "            \n",
    "# Backtracking\n",
    "    states_path = np.zeros(T, dtype = np.int32)\n",
    "    states_path[T-1] = np.argmax(delta[T-1]) # last state\n",
    "    \n",
    "    for t in range(T-2, -1,-1):         # states of (last-1)th to 0th time step\n",
    "        states_path[t] = alpha[t+1, states_path[t+1]]\n",
    "    \n",
    "    return states_path\n",
    "    \n",
    "Most_prob_path = viterbi(x,P,E,pi)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(obs_seq):\n",
    "    \n",
    "    T = len(obs_seq) # Number of time steps \n",
    "    N = P.shape[0]   # number of states\n",
    "    beta = np.zeros((T,N))  # forward variable\n",
    "    beta[0] = pi * O[:, obs_seq[0]]\n",
    "    \n",
    "    for t in range(1,T):\n",
    "        beta[t] = beta[t-1].dot(P) * E[:,obs_seq[t]]\n",
    "        \n",
    "    return beta\n",
    "\n",
    "def prob(obs_seq):\n",
    "    \n",
    "    return forward(obs_seq)[-1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1377817622103544e-232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob(obs_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(obs_seq):\n",
    "    \n",
    "    T = len(obs_seq) # Number of time steps \n",
    "    N = P.shape[0]   # number of states\n",
    "    \n",
    "    alpha = np.zeros((N,T))\n",
    "    alpha[:,-1:] =1\n",
    "    \n",
    "    for t in reversed(range(T-1)):\n",
    "        for n in range(N):\n",
    "            \n",
    "            alpha[n,t] = np.sum(beta[:,t+1] * P[n,:] * E[:, obs_seq[t+1]])\n",
    "            \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior(obs_seq):\n",
    "    \n",
    "    forward = forward(obs_seq)\n",
    "    backward = backward(obs_seq)\n",
    "    obs_prob = prob(obs_seq)\n",
    "    \n",
    "    return (np.multiply(forward,backward.T)/ obs_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov chain simulated path: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0] \n",
      "\n",
      "Viterbi most likely path: \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print ('Markov chain simulated path:','\\n', hid_seq,'\\n') \n",
    "print ('Viterbi most likely path:','\\n',Most_prob_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 1, 3, 3, 4, 3, 2, 3, 0, 5, 5, 0, 3, 1, 4, 4, 3, 1, 2, 2, 2,\n",
       "       0, 5, 1, 3, 3, 0, 1, 2, 4, 4, 4, 2, 4, 1, 3, 0, 4, 3, 2, 5, 2, 0,\n",
       "       2, 2, 3, 1, 0, 3, 0, 4, 0, 3, 0, 4, 2, 5, 1, 4, 2, 5, 1, 2, 2, 4,\n",
       "       2, 5, 5, 3, 4, 3, 3, 0, 5, 5, 4, 5, 5, 1, 0, 5, 5, 5, 1, 5, 4, 0,\n",
       "       3, 5, 1, 1, 5, 1, 0, 3, 1, 5, 5, 4, 5, 0, 3, 1, 5, 1, 3, 2, 5, 4,\n",
       "       5, 5, 0, 4, 4, 5, 4, 2, 3, 3, 5, 5, 5, 4, 5, 2, 2, 3, 1, 5, 1, 2,\n",
       "       0, 2, 5, 0, 3, 1, 1, 4, 2, 5, 4, 1, 3, 1, 5, 1, 5, 1, 5, 0, 0, 0,\n",
       "       1, 4, 4, 3, 3, 4, 2, 5, 0, 3, 5, 4, 2, 4, 3, 3, 5, 4, 5, 1, 4, 1,\n",
       "       0, 1, 3, 3, 5, 0, 4, 5, 2, 2, 0, 5, 0, 2, 3, 2, 2, 4, 1, 5, 0, 3,\n",
       "       5, 5, 1, 3, 3, 3, 5, 4, 5, 0, 0, 5, 0, 5, 3, 3, 1, 0, 5, 0, 2, 5,\n",
       "       5, 5, 5, 4, 3, 5, 1, 5, 1, 5, 4, 2, 2, 1, 1, 0, 1, 5, 1, 5, 5, 0,\n",
       "       4, 0, 2, 2, 5, 3, 2, 2, 5, 5, 3, 3, 2, 5, 2, 4, 1, 0, 0, 1, 3, 1,\n",
       "       2, 1, 4, 2, 2, 3, 0, 1, 4, 4, 0, 2, 3, 4, 3, 2, 3, 4, 0, 0, 5, 2,\n",
       "       0, 3, 5, 1, 3, 0, 0, 5, 5, 3, 3, 4, 1, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "$y=mx+c$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "$y=mx+c$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
